{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd7b749b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 11:31:22\n"
     ]
    }
   ],
   "source": [
    "### GIS-based bikeshare optimization program ###\n",
    "################################################################################################\n",
    "''' Copyright (C) 2023 by Hannah DeBruin\n",
    "Released under the GNU General Public License, version 2.\n",
    "-------------------------------------------------------\n",
    "The code is entirely and originally written by Hannah DeBruin\n",
    "Contact: hannah.debruin@gmail.com\n",
    "-------------------------------------------------------\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 2 of the License, or\n",
    "(at your option) any later version.\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program. If not, see <http://www.gnu.org/licenses/>. \n",
    "\n",
    "The .csv files referenced in this text are outputs of the ArcGIS Pro\n",
    "\"Bikeshare Optimization Data Tool\" which can be found at the link:\n",
    "<https://github.umn.edu/TransitLab/bikeshare-station-optimization> '''\n",
    "################################################################################################\n",
    "################################################################################################\n",
    "################################################################################################\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "import cplex\n",
    "from cplex.exceptions import CplexError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18068bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docplex.mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef9a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edc588f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c214cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docplex.mp.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ad99036",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model('bike_station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab074681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifying total budgeted number of stations\n",
    "N_tot = 40\n",
    "#specifying minimum number stations meeting each goal\n",
    "n_reg = 10\n",
    "n_rec = 6\n",
    "n_eq = 10\n",
    "n_trans = 9\n",
    "n_ppp = 5\n",
    "N_CL = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad50fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determining total number of grid spaces\n",
    "import csv\n",
    "\n",
    "f = open('regular_use_CL.csv', newline='')\n",
    "n = len(f.readlines())\n",
    "    \n",
    "fR = range(0,n-1)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18bae27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate Locations Subset Size: 1283\n"
     ]
    }
   ],
   "source": [
    "# variables associated with each grid space\n",
    "fw_reg = m.continuous_var_list(fR, lb=None, ub=None, name=\"fW_reg\", key_format=None)\n",
    "fb_reg = m.binary_var_list(fR, lb=None, ub=None, name=\"fb_reg\", key_format=None)\n",
    "fb_reg = [0]*(n-1)\n",
    "fw_rec = m.continuous_var_list(fR, lb=None, ub=None, name=\"fW_rec\", key_format=None)\n",
    "fb_rec = m.binary_var_list(fR, lb=None, ub=None, name=\"fb_rec\", key_format=None)\n",
    "fb_rec = [0]*(n-1)\n",
    "fw_eq = m.continuous_var_list(fR, lb=None, ub=None, name=\"fW_eq\", key_format=None)\n",
    "fb_eq = m.binary_var_list(fR, lb=None, ub=None, name=\"fb_eq\", key_format=None)\n",
    "fb_eq = [0]*(n-1)\n",
    "fw_trans = m.continuous_var_list(fR, lb=None, ub=None, name=\"fW_trans\", key_format=None)\n",
    "fb_trans = m.binary_var_list(fR, lb=None, ub=None, name=\"fb_trans\", key_format=None)\n",
    "fb_trans = [0]*(n-1)\n",
    "fw_ppp = m.continuous_var_list(fR, lb=None, ub=None, name=\"fW_ppp\", key_format=None)\n",
    "fb_ppp = m.binary_var_list(fR, lb=None, ub=None, name=\"fb_ppp\", key_format=None)\n",
    "fb_ppp = [0]*(n-1)\n",
    "ffid = m.integer_var_list(fR, lb=None, ub=None, name=\"fFid\", key_format=None)\n",
    "flat = m.continuous_var_list(fR, lb=None, ub=None, name=\"flat\", key_format=None)\n",
    "flong = m.continuous_var_list(fR, lb=None, ub=None, name=\"flong\", key_format=None)\n",
    "\n",
    "#reading in point data for regular use\n",
    "with open('regular_use_CL.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = list(reader)\n",
    "    for i in fR:\n",
    "        ffid[i] = int(data[i+1][1])\n",
    "        fw_reg[i] = float(data[i+1][2])\n",
    "        flat[i] = float(data[i+1][3])\n",
    "        flong[i] = float(data[i+1][4])\n",
    "        if i < N_CL: #if in top-ranking locations\n",
    "            fb_reg[i] = 1\n",
    "\n",
    "f.close()\n",
    "\n",
    "#adding in point data for recreational use\n",
    "with open('recreational_use_CL.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = list(reader)\n",
    "    for i in fR:\n",
    "        for j in fR:\n",
    "            if ffid[i] == int(data[j+1][1]):\n",
    "                fw_rec[i] = float(data[j+1][2])\n",
    "                if j < N_CL: #if in top-ranking locations\n",
    "                    fb_rec[i] = 1\n",
    "f.close()\n",
    "\n",
    "#adding in point data for equity\n",
    "with open('equity_CL.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = list(reader)\n",
    "    for i in fR:\n",
    "        for j in fR:\n",
    "            if ffid[i] == int(data[j+1][1]):\n",
    "                fw_eq[i] = float(data[j+1][2])\n",
    "                if j< N_CL: #if in top-ranking locations\n",
    "                    fb_eq[i] = 1\n",
    "f.close()\n",
    "\n",
    "\n",
    "#adding in point data for transportation network\n",
    "with open('trans_net_CL.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = list(reader)\n",
    "    for i in fR:\n",
    "        for j in fR:\n",
    "            if ffid[i] == int(data[j+1][1]):\n",
    "                fw_trans[i] = float(data[j+1][2])\n",
    "                if j< N_CL: #if in top-ranking locations\n",
    "                    fb_trans[i] = 1\n",
    "f.close()\n",
    "\n",
    "#adding in point data for partnership opportunities\n",
    "with open('partnerships_CL.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    data = list(reader)\n",
    "    for i in fR:\n",
    "        for j in fR:\n",
    "            if ffid[i] == int(data[j+1][1]):\n",
    "                fw_ppp[i] = float(data[j+1][2])\n",
    "                if j< N_CL: #if in top-ranking locations\n",
    "                    fb_ppp[i] = 1\n",
    "f.close()\n",
    "\n",
    "#creating subset of just top-ranking locations\n",
    "subset_size = 0\n",
    "for i in fR:\n",
    "    if (fb_reg[i] + fb_rec[i] + fb_eq[i] + fb_trans[i] + fb_ppp[i]) >= 1:\n",
    "        subset_size = subset_size + 1\n",
    "\n",
    "\n",
    "R = range(0,subset_size)\n",
    "\n",
    "print(\"Candidate Locations Subset Size:\",subset_size)\n",
    "\n",
    "# variables associated with each subset candidate location\n",
    "w_reg = m.continuous_var_list(R, lb=None, ub=None, name=\"W_reg\", key_format=None)\n",
    "b_reg = m.binary_var_list(R, lb=None, ub=None, name=\"b_reg\", key_format=None)\n",
    "w_rec = m.continuous_var_list(R, lb=None, ub=None, name=\"W_rec\", key_format=None)\n",
    "b_rec = m.binary_var_list(R, lb=None, ub=None, name=\"b_rec\", key_format=None)\n",
    "w_eq = m.continuous_var_list(R, lb=None, ub=None, name=\"W_eq\", key_format=None)\n",
    "b_eq = m.binary_var_list(R, lb=None, ub=None, name=\"b_eq\", key_format=None)\n",
    "w_trans = m.continuous_var_list(R, lb=None, ub=None, name=\"W_trans\", key_format=None)\n",
    "b_trans = m.binary_var_list(R, lb=None, ub=None, name=\"b_trans\", key_format=None)\n",
    "w_ppp = m.continuous_var_list(R, lb=None, ub=None, name=\"W_ppp\", key_format=None)\n",
    "b_ppp = m.binary_var_list(R, lb=None, ub=None, name=\"b_ppp\", key_format=None)\n",
    "fid = m.integer_var_list(R, lb=None, ub=None, name=\"Fid\", key_format=None)\n",
    "w = m.continuous_var_list(R, lb=None, ub=None, name=\"W\", key_format=None)\n",
    "lat = m.continuous_var_list(fR, lb=None, ub=None, name=\"lat\", key_format=None)\n",
    "long = m.continuous_var_list(fR, lb=None, ub=None, name=\"long\", key_format=None)\n",
    "\n",
    "#assigning overall weight, all data to candidate location subset\n",
    "j = 0\n",
    "for i in fR:\n",
    "    if (fb_reg[i] + fb_rec[i] + fb_eq[i] + fb_trans[i] + fb_ppp[i]) >= 1:\n",
    "        fid[j] = ffid[i]\n",
    "        w_reg[j] = fw_reg[i]\n",
    "        b_reg[j] = fb_reg[i]\n",
    "        w_rec[j] = fw_rec[i]\n",
    "        b_rec[j] = fb_rec[i]\n",
    "        w_eq[j] = fw_eq[i]\n",
    "        b_eq[j] = fb_eq[i]\n",
    "        w_trans[j] = fw_trans[i]\n",
    "        b_trans[j] = fb_trans[i]\n",
    "        w_ppp[j] = fw_ppp[i]\n",
    "        b_ppp[j] = fb_ppp[i]\n",
    "        lat[j] = flat[i]\n",
    "        long[j] = flong[i]\n",
    "        w[j] = ((n_reg/N_tot)*fw_reg[i]) + ((n_rec/N_tot)*fw_rec[i]) + ((n_eq/N_tot)*fw_eq[i]) + ((n_trans/N_tot)*fw_trans[i])+ ((n_ppp/N_tot)*fw_ppp[i])\n",
    "        j = j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b69a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining variable for yes/no in each grid cell\n",
    "x = m.binary_var_list(R, lb=None, ub=None, name=\"X\", key_format=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4072e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "docplex.mp.LinearConstraint[](X_0+X_1+X_2+X_3+X_5+X_6+X_9+X_29+X_33+X_38+X_74+X_80+X_83+X_87+X_90+X_91+X_92+X_99+X_126+X_134+X_160+X_164+X_167+X_168+X_171+X_172+X_174+X_175+X_177+X_181+X_185+X_192+X_194+X_197+X_216+X_217+X_219+X_225+X_232+X_252+X_257+X_265+X_268+X_272+X_281+X_289+X_291+X_298+X_301+X_309+X_312+X_313+X_314+X_319+X_325+X_331+X_334+X_342+X_346+X_348+X_351+X_353+X_356+X_360+X_361+X_371+X_377+X_382+X_389+X_396+X_403+X_404+X_405+X_406+X_408+X_416+X_417+X_420+X_423+X_424+X_425+X_426+X_427+X_428+X_430+X_432+X_433+X_434+X_435+X_436+X_437+X_438+X_439+X_440+X_442+X_443+X_445+X_447+X_448+X_453+X_456+X_459+X_460+X_465+X_467+X_469+X_470+X_476+X_478+X_480+X_482+X_483+X_484+X_486+X_487+X_490+X_491+X_492+X_493+X_494+X_495+X_496+X_497+X_503+X_504+X_508+X_512+X_517+X_519+X_520+X_523+X_524+X_525+X_527+X_528+X_531+X_533+X_534+X_538+X_542+X_544+X_547+X_550+X_551+X_552+X_553+X_554+X_555+X_561+X_562+X_564+X_566+X_570+X_573+X_579+X_585+X_588+X_590+X_599+X_601+X_605+X_607+X_618+X_620+X_621+X_622+X_629+X_631+X_635+X_638+X_640+X_648+X_651+X_655+X_656+X_658+X_660+X_662+X_663+X_665+X_666+X_669+X_670+X_675+X_679+X_681+X_683+X_684+X_686+X_687+X_689+X_690+X_694+X_695+X_696+X_698+X_699+X_700+X_701+X_703+X_705+X_707+X_711+X_713+X_715+X_717+X_722+X_723+X_724+X_725+X_726+X_727+X_728+X_729+X_730+X_731+X_734+X_737+X_739+X_743+X_745+X_746+X_748+X_749+X_751+X_752+X_754+X_755+X_756+X_762+X_763+X_765+X_766+X_767+X_776+X_777+X_783+X_794+X_795+X_796+X_797+X_801+X_805+X_806+X_807+X_810+X_811+X_815+X_818+X_820+X_821+X_822+X_823+X_824+X_825+X_828+X_834+X_835+X_837+X_838+X_841+X_842+X_850+X_856+X_861+X_864+X_869+X_875+X_877+X_880+X_893+X_894+X_903+X_904+X_908+X_909+X_912+X_914+X_916+X_917+X_922+X_924+X_926+X_928+X_929+X_930+X_934+X_935+X_937+X_949+X_951+X_952+X_953+X_956+X_957+X_959+X_960+X_971+X_977+X_978+X_982+X_983+X_985+X_991+X_992+X_993+X_995+X_1003+X_1004+X_1005+X_1007+X_1008+X_1012+X_1022+X_1023+X_1026+X_1029+X_1031+X_1039+X_1040+X_1041+X_1042+X_1049+X_1050+X_1053+X_1058+X_1059+X_1062+X_1063+X_1064+X_1066+X_1068+X_1072+X_1074+X_1076+X_1077+X_1082+X_1083+X_1090+X_1091+X_1097+X_1098+X_1099+X_1100+X_1101+X_1102+X_1104+X_1105+X_1106+X_1107+X_1108+X_1109+X_1115+X_1116+X_1126+X_1127+X_1128+X_1129+X_1133+X_1136+X_1138+X_1142+X_1145+X_1147+X_1157+X_1159+X_1162+X_1163+X_1165+X_1168+X_1170+X_1174+X_1175+X_1176+X_1178+X_1179+X_1181+X_1184+X_1185+X_1200+X_1201+X_1203+X_1207+X_1208+X_1209+X_1216+X_1224+X_1225+X_1226+X_1227+X_1228+X_1229+X_1231+X_1232+X_1233+X_1234+X_1238+X_1239+X_1240+X_1241,GE,5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max number of stations constraint\n",
    "m.add_constraint(m.sum(x) <= N_tot)\n",
    "# min number of stations for each goal constraint\n",
    "m.add_constraint(m.dot(x,b_reg) >= n_reg)\n",
    "m.add_constraint(m.dot(x,b_rec) >= n_rec)\n",
    "m.add_constraint(m.dot(x,b_eq) >= n_eq)\n",
    "m.add_constraint(m.dot(x,b_trans) >= n_trans)\n",
    "m.add_constraint(m.dot(x,b_ppp) >= n_ppp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e74babfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 10)\n",
      "range(0, 6)\n",
      "range(0, 10)\n",
      "range(0, 9)\n",
      "range(0, 5)\n"
     ]
    }
   ],
   "source": [
    "#reading in zone data\n",
    "\n",
    "#regular use\n",
    "import csv\n",
    "zf_reg = open('regular_use_ZT.csv', newline='')\n",
    "zn_reg = len(zf_reg.readlines())\n",
    "zR_reg = range(0,zn_reg-1)\n",
    "zf_reg.close()\n",
    "\n",
    "s_1_reg = m.integer_var_list(zR_reg, lb=None, ub=None, name=\"S_1_reg\", key_format=None)\n",
    "s_2_reg = m.integer_var_list(zR_reg, lb=None, ub=None, name=\"S_2_reg\", key_format=None)\n",
    "zfid_reg = m.integer_var_list(zR_reg, lb=None, ub=None, name=\"zFid_reg\", key_format=None)\n",
    "\n",
    "with open('regular_use_ZT.csv', 'r') as zf_reg:\n",
    "    reader = csv.reader(zf_reg)\n",
    "    data = list(reader)\n",
    "    for i in zR_reg:\n",
    "        zfid_reg[i] = int(data[i+1][2])\n",
    "        s_1_reg[i] = int(data[i+1][6])\n",
    "        s_2_reg[i] = int(data[i+1][9])\n",
    "        \n",
    "#determine number of zones\n",
    "nzones_reg = m.max(m.max(s_1_reg),m.max(s_2_reg))\n",
    "Z_reg = range(0,nzones_reg)   \n",
    "print(Z_reg)\n",
    "\n",
    "#recreational use\n",
    "import csv\n",
    "zf_rec = open('recreational_use_ZT.csv', newline='')\n",
    "zn_rec = len(zf_rec.readlines())\n",
    "zR_rec = range(0,zn_rec-1)\n",
    "zf_rec.close()\n",
    "\n",
    "s_1_rec = m.integer_var_list(zR_rec, lb=None, ub=None, name=\"S_1_rec\", key_format=None)\n",
    "s_2_rec = m.integer_var_list(zR_rec, lb=None, ub=None, name=\"S_2_rec\", key_format=None)\n",
    "zfid_rec = m.integer_var_list(zR_rec, lb=None, ub=None, name=\"zFid_rec\", key_format=None)\n",
    "\n",
    "with open('recreational_use_ZT.csv', 'r') as zf_rec:\n",
    "    reader = csv.reader(zf_rec)\n",
    "    data = list(reader)\n",
    "    for i in zR_rec:\n",
    "        zfid_rec[i] = int(data[i+1][2])\n",
    "        s_1_rec[i] = int(data[i+1][6])\n",
    "        s_2_rec[i] = int(data[i+1][9])\n",
    "        \n",
    "#determine number of zones\n",
    "nzones_rec = m.max(m.max(s_1_rec),m.max(s_2_rec))\n",
    "Z_rec = range(0,nzones_rec)  \n",
    "print(Z_rec)\n",
    "\n",
    "#equity\n",
    "import csv\n",
    "zf_eq = open('equity_ZT.csv', newline='')\n",
    "zn_eq = len(zf_eq.readlines())\n",
    "zR_eq = range(0,zn_eq-1)\n",
    "zf_eq.close()\n",
    "\n",
    "s_1_eq = m.integer_var_list(zR_eq, lb=None, ub=None, name=\"S_1_eq\", key_format=None)\n",
    "s_2_eq = m.integer_var_list(zR_eq, lb=None, ub=None, name=\"S_2_eq\", key_format=None)\n",
    "zfid_eq = m.integer_var_list(zR_eq, lb=None, ub=None, name=\"zFid_eq\", key_format=None)\n",
    "\n",
    "with open('equity_ZT.csv', 'r') as zf_eq:\n",
    "    reader = csv.reader(zf_eq)\n",
    "    data = list(reader)\n",
    "    for i in zR_eq:\n",
    "        zfid_eq[i] = int(data[i+1][2])\n",
    "        s_1_eq[i] = int(data[i+1][6])\n",
    "        s_2_eq[i] = int(data[i+1][9])\n",
    "        \n",
    "#determine number of zones\n",
    "nzones_eq = m.max(m.max(s_1_eq),m.max(s_2_eq))\n",
    "Z_eq = range(0,nzones_eq)   \n",
    "print(Z_eq)\n",
    "\n",
    "#transportation network\n",
    "import csv\n",
    "zf_trans = open('trans_net_ZT.csv', newline='')\n",
    "zn_trans = len(zf_trans.readlines())\n",
    "zR_trans = range(0,zn_trans-1)\n",
    "zf_trans.close()\n",
    "\n",
    "s_1_trans = m.integer_var_list(zR_trans, lb=None, ub=None, name=\"S_1_trans\", key_format=None)\n",
    "s_2_trans = m.integer_var_list(zR_trans, lb=None, ub=None, name=\"S_2_trans\", key_format=None)\n",
    "zfid_trans = m.integer_var_list(zR_trans, lb=None, ub=None, name=\"zFid_trans\", key_format=None)\n",
    "\n",
    "with open('trans_net_ZT.csv', 'r') as zf_trans:\n",
    "    reader = csv.reader(zf_trans)\n",
    "    data = list(reader)\n",
    "    for i in zR_trans:\n",
    "        zfid_trans[i] = int(data[i+1][2])\n",
    "        s_1_trans[i] = int(data[i+1][6])\n",
    "        s_2_trans[i] = int(data[i+1][9])\n",
    "        \n",
    "#determine number of zones\n",
    "nzones_trans = m.max(m.max(s_1_trans),m.max(s_2_trans))\n",
    "Z_trans = range(0,nzones_trans)   \n",
    "print(Z_trans)\n",
    "\n",
    "\n",
    "#partnership opportunities\n",
    "import csv\n",
    "zf_ppp = open('partnerships_ZT.csv', newline='')\n",
    "zn_ppp = len(zf_ppp.readlines())\n",
    "zR_ppp = range(0,zn_ppp-1)\n",
    "zf_ppp.close()\n",
    "\n",
    "s_1_ppp = m.integer_var_list(zR_ppp, lb=None, ub=None, name=\"S_1_ppp\", key_format=None)\n",
    "s_2_ppp = m.integer_var_list(zR_ppp, lb=None, ub=None, name=\"S_2_ppp\", key_format=None)\n",
    "zfid_ppp = m.integer_var_list(zR_ppp, lb=None, ub=None, name=\"zFid_ppp\", key_format=None)\n",
    "\n",
    "with open('partnerships_ZT.csv', 'r') as zf_ppp:\n",
    "    reader = csv.reader(zf_ppp)\n",
    "    data = list(reader)\n",
    "    for i in zR_ppp:\n",
    "        zfid_ppp[i] = int(data[i+1][2])\n",
    "        s_1_ppp[i] = int(data[i+1][6])\n",
    "        s_2_ppp[i] = int(data[i+1][9])\n",
    "        \n",
    "#determine number of zones\n",
    "nzones_ppp = m.max(m.max(s_1_ppp),m.max(s_2_ppp))\n",
    "Z_ppp = range(0,nzones_ppp)   \n",
    "print(Z_ppp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85820ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cover each set constraint\n",
    "\n",
    "#regular use\n",
    "count_reg = m.integer_var_list(Z_reg, lb=None, ub=None, name=\"count_reg\", key_format=None)\n",
    "count_reg = [0]*nzones_reg\n",
    "\n",
    "for i in zR_reg:\n",
    "    for j in R:\n",
    "        for k in Z_reg:\n",
    "            if zfid_reg[i] == fid[j]:\n",
    "                if s_1_reg[i] == (k+1) or s_2_reg[i] == (k+1):\n",
    "                    count_reg[k] = count_reg[k] + x[j]\n",
    "                    \n",
    "for i in Z_reg:\n",
    "    m.add_constraint(count_reg[i] >= 1)\n",
    "    \n",
    "#recreational use\n",
    "count_rec = m.integer_var_list(Z_rec, lb=None, ub=None, name=\"count_rec\", key_format=None)\n",
    "count_rec = [0]*nzones_rec\n",
    "\n",
    "for i in zR_rec:\n",
    "    for j in R:\n",
    "        for k in Z_rec:\n",
    "            if zfid_rec[i] == fid[j]:\n",
    "                if s_1_rec[i] == (k+1) or s_2_rec[i] == (k+1):\n",
    "                    count_rec[k] = count_rec[k] + x[j]\n",
    "                    \n",
    "for i in Z_rec:\n",
    "    m.add_constraint(count_rec[i] >= 1) \n",
    "    \n",
    "#equity\n",
    "count_eq = m.integer_var_list(Z_eq, lb=None, ub=None, name=\"count_eq\", key_format=None)\n",
    "count_eq = [0]*nzones_eq\n",
    "\n",
    "for i in zR_eq:\n",
    "    for j in R:\n",
    "        for k in Z_eq:\n",
    "            if zfid_eq[i] == fid[j]:\n",
    "                if s_1_eq[i] == (k+1) or s_2_eq[i] == (k+1):\n",
    "                    count_eq[k] = count_eq[k] + x[j]\n",
    "                    \n",
    "for i in Z_eq:\n",
    "    m.add_constraint(count_eq[i] >= 1) \n",
    "    \n",
    "#transportation network\n",
    "count_trans = m.integer_var_list(Z_trans, lb=None, ub=None, name=\"count_trans\", key_format=None)\n",
    "count_trans = [0]*nzones_trans\n",
    "\n",
    "for i in zR_trans:\n",
    "    for j in R:\n",
    "        for k in Z_trans:\n",
    "            if zfid_trans[i] == fid[j]:\n",
    "                if s_1_trans[i] == (k+1) or s_2_trans[i] == (k+1):\n",
    "                    count_trans[k] = count_trans[k] + x[j]\n",
    "                    \n",
    "for i in Z_trans:\n",
    "    m.add_constraint(count_trans[i] >= 1) \n",
    "    \n",
    "#partnership opportunities\n",
    "count_ppp = m.integer_var_list(Z_ppp, lb=None, ub=None, name=\"count_ppp\", key_format=None)\n",
    "count_ppp = [0]*nzones_ppp\n",
    "\n",
    "for i in zR_ppp:\n",
    "    for j in R:\n",
    "        for k in Z_ppp:\n",
    "            if zfid_ppp[i] == fid[j]:\n",
    "                if s_1_ppp[i] == (k+1) or s_2_ppp[i] == (k+1):\n",
    "                    count_ppp[k] = count_ppp[k] + x[j]\n",
    "                    \n",
    "for i in Z_ppp:\n",
    "    m.add_constraint(count_ppp[i] >= 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84c9e084",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#read distance file\n",
    "df = open('DistanceTable.csv', 'r')\n",
    "dn = len(df.readlines())\n",
    "\n",
    "dR = range(0,dn-1)\n",
    "\n",
    "df.close()\n",
    "\n",
    "o = m.integer_var_list(dR, lb=None, ub=None, name=\"o\", key_format=None)\n",
    "d = m.integer_var_list(dR, lb=None, ub=None, name=\"d\", key_format=None)\n",
    "\n",
    "with open('DistanceTable.csv', newline='') as df:\n",
    "    reader = csv.reader(df)\n",
    "    data = list(reader)\n",
    "    for i in dR:\n",
    "        o[i] = int(data[i+1][1])\n",
    "        d[i] = int(data[i+1][2])\n",
    "        \n",
    "for i in dR:\n",
    "    for j in R:\n",
    "        if o[i] == fid[j]:\n",
    "            for k in R:\n",
    "                if d[i] == fid[k]:\n",
    "                    m.add_constraint(x[j]+x[k] <= 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fc56668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution for: bike_station\n",
      "objective: 2172.9\n",
      "X_1=1\n",
      "X_2=1\n",
      "X_18=1\n",
      "X_24=1\n",
      "X_36=1\n",
      "X_37=1\n",
      "X_54=1\n",
      "X_57=1\n",
      "X_67=1\n",
      "X_70=1\n",
      "X_80=1\n",
      "X_126=1\n",
      "X_175=1\n",
      "X_184=1\n",
      "X_202=1\n",
      "X_334=1\n",
      "X_348=1\n",
      "X_358=1\n",
      "X_372=1\n",
      "X_405=1\n",
      "X_410=1\n",
      "X_420=1\n",
      "X_421=1\n",
      "X_440=1\n",
      "X_443=1\n",
      "X_454=1\n",
      "X_466=1\n",
      "X_478=1\n",
      "X_486=1\n",
      "X_504=1\n",
      "X_539=1\n",
      "X_583=1\n",
      "X_589=1\n",
      "X_593=1\n",
      "X_638=1\n",
      "X_687=1\n",
      "X_693=1\n",
      "X_722=1\n",
      "X_780=1\n",
      "X_895=1\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'parameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m solution\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(solution)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mparameters\u001b[49m\u001b[38;5;241m.\u001b[39mmip\u001b[38;5;241m.\u001b[39mtolerances\u001b[38;5;241m.\u001b[39mmipgap)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parameters' is not defined"
     ]
    }
   ],
   "source": [
    "obj = m.dot(x,w)\n",
    "m.maximize(obj)\n",
    "solution = m.solve()\n",
    "assert solution\n",
    "print(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae770359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing solutions\n",
    "with open('solution.csv','w',newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"fid\",\"x\",\"b_reg\",\"b_rec\",\"b_eq\",\"b_trans\",\"b_ppp\",\"lat\",\"long\"])\n",
    "    for i in R:\n",
    "        if solution[x[i]] == 1:\n",
    "            writer.writerow([fid[i],solution[x[i]],b_reg[i],b_rec[i],b_eq[i],b_trans[i],b_ppp[i],lat[i],long[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0d029ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 11:40:22\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
